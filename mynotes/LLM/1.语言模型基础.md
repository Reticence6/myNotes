# 语言的建模

1. 将语言建模为一系列词元(token)组成的序列数据。词元是不可再拆分的最小语义单位。

2. 语言模型旨在预测一个词元或词元序列出现的概率。现有模型通常基于规则、统计或学习来构建。

3. 语言模型的概率预测与上下文和语料库有关

4. 条件概率链式法则
   $$
   P(\{w_1, w_2, \ldots, w_N\}) = P(w_1) \cdot P(w_2 | w_1) \cdot P(w_3 | w_1, w_2) \cdots P(w_N | w_1, \ldots, w_{N-2}, w_{N-1})
   $$

5. n-阶马尔科夫假设：当前状态只与前n个状态有关

6. 发展历史：基于规则的年代-->基于统计的年代-->基于学习的年代

# 基于统计的语言模型

最具代表性的是：n-grams语言模型

- n-grams指的是长度为n的此序列
- n-grams语言模型通过依次统计文本中的n-gram及其对应的(n-1)-gram在语料库中出现的相对频率来计算文本$\omega_{1:N}$。出现的概率。计算公式如下所示:
- n代表了拟合语料库的能力与对未知文本的泛化能力之间的权衡。
  - 当n过大时，语料库中难以找到与n-gram一模一样的词序列，可能出现大量“零概率”现象
  - 当n过小时，n-gram难以承载足够的语言信息，不足以反应语料库的特性
  - 因此，在n-grams语言模型中，n的值是影响性能的关键因素
  - 上述的“零概率”现象可以通过平滑(Smoothing)技术进行改善
- n-grams语言模型是在n阶马尔可夫假设下，对语料库中出现的长度为n的词序列出现概率的极大似然估计。